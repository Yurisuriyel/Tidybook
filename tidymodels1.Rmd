---
title: "tidymodels"
author: "Linze Yu"
date: "`r Sys.Date()`"
output:
  rmdformats::downcute:
    self_contained: TRUE
    default_style: "light"
    downcute_theme: "default"
    fig_width: 7
    fig_height: 5
    use_bookdown: TRUE
    gallery: TRUE
    lightbox: TRUE
    highlight: tango
editor_options: 
  markdown: 
    wrap: 72
---

```{r, 代码全局设置, echo = F}
knitr::opts_chunk$set(warning = F, error = F, message = F, prompt = F, comment = "", echo = T, dpi = 200, collapse = F, fig.align = "left", dev = "png")
# , eval = F代码显示不运行
# , include = F代码运行, 不显示代码和结果
# , echo = T 显示代码块
# , prompt = T使用>开始代码
# , comment = ""结果不使用##
# , collapse = T#代码合并结果
# , out.width/out.height = 0.8缩放
# , fig.align = "left","center","right"对齐方式
# , dev = "pdf","png","svg","jpeg"记录设备
# , cache = T
```

## 加载包
```{r 加载包}

```

library("YuriR") #
# library("mlr3verse") #
library("tidymodels") #
library("igraph")
 
library("broom.mixed")
library("dotwhisker")
# remotes::install_github("fsolt/dotwhisker")
library("rstanarm")
library("MASS") #
library("nnet") #
# library("survival")#
library("AER") #
library("glmnet") #
library("randomForest") # 随机森林
library("caret")
library("pROC")

# 海胆
```{r}
import("D:/desktop/book/tidybook/data/tidymodels/urchins.xlsx") %>%
  setNames(c("food_regime", "initial_volume", "width")) %>%
  mutate(food_regime = factor(food_regime, levels = c("Initial", "Low", "High"))) -> urchins
```

```{r}
urchins %>%
  ggplot(., aes(x = initial_volume, y = width, col = food_regime, fill = food_regime)) +
  geom_point(shape = 21, size = 2, stroke = 1) +
  geom_smooth(method = lm, se = F) +
  scale_color_manual(values = cols) +
  scale_fill_manual(values = fills) +
  Yuri_theme+
  theme(legend.position = (c(0.2, 0.95)))
```

```{r}
linear_reg()
```

```{r}
linear_reg() %>% 
  set_engine("keras")
```

```{r}
lm_mod <- linear_reg()
```

```{r}
lm_fit <- 
  lm_mod %>% 
  fit(width ~ initial_volume * food_regime, data = urchins)
lm_fit
```

```{r}
tidy(lm_fit)
```

```{r}
tidy(lm_fit) %>% 
  dwplot(dot_args = list(size = 2, color = "black"),
         whisker_args = list(color = "black"),
         vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))
```

```{r}
new_points <- expand.grid(initial_volume = 20, 
                          food_regime = c("Initial", "Low", "High"))
new_points
```

```{r}
mean_pred <- predict(lm_fit, new_data = new_points)
mean_pred
```

```{r}
conf_int_pred <- predict(lm_fit, 
                         new_data = new_points, 
                         type = "conf_int")
conf_int_pred
```

```{r}
plot_data <- 
  new_points %>% 
  bind_cols(mean_pred) %>% 
  bind_cols(conf_int_pred)
```

```{r}
ggplot(plot_data, aes(x = food_regime)) + 
  geom_point(aes(y = .pred)) + 
  geom_errorbar(aes(ymin = .pred_lower, 
                    ymax = .pred_upper),
                width = .2) + 
  labs(y = "urchin size")
```

```{r}
prior_dist <- rstanarm::student_t(df = 1)
set.seed(2022)
bayes_mod <-   linear_reg() %>% 
  set_engine("stan", 
             prior_intercept = prior_dist, 
             prior = prior_dist) 
```

```{r}
bayes_fit <- 
  bayes_mod %>% 
  fit(width ~ initial_volume * food_regime, data = urchins)

print(bayes_fit, digits = 5)
```

```{r}
tidy(bayes_fit, conf.int = TRUE)
```

```{r}
bayes_plot_data <- 
  new_points %>% 
  bind_cols(predict(bayes_fit, new_data = new_points)) %>% 
  bind_cols(predict(bayes_fit, new_data = new_points, type = "conf_int"))

ggplot(bayes_plot_data, aes(x = food_regime)) + 
  geom_point(aes(y = .pred)) + 
  geom_errorbar(aes(ymin = .pred_lower, ymax = .pred_upper), width = .2) + 
  labs(y = "urchin size") + 
  ggtitle("Bayesian model with t(1) prior distribution")
```

```{r}
urchins %>% 
  group_by(food_regime) %>% 
  summarize(med_vol = median(initial_volume))
```

```{r}
bayes_mod %>% 
  fit(width ~ initial_volume * food_regime, data = urchins)
```

```{r}
ggplot(urchins,
       aes(initial_volume, width)) +      # returns a ggplot object 
  geom_jitter() +                         # same
  geom_smooth(method = lm, se = FALSE) +  # same                    
  labs(x = "Volume", y = "Width") 
```






























# mlr3
## k近邻算法
```{r}
import("D:/desktop/book/tidybook/data/tidymodels/diabetes.xlsx") %>%
  data.table() -> data
data
data %>%
  ggplot(., aes(x = glucose, y = insulin, color = class)) +
  geom_point(size = 2, stroke = 1, fill = NA, shape = 21) +
  scale_color_manual(values = cols) +
  scale_fill_manual(values = fills) +
  Yuri_theme
data %>%
  ggplot(., aes(x = sspg, y = insulin, color = class)) +
  geom_point(size = 2, stroke = 1, fill = NA, shape = 21) +
  scale_color_manual(values = cols) +
  scale_fill_manual(values = fills) +
  Yuri_theme
data %>%
  ggplot(., aes(x = sspg, y = glucose, color = class)) +
  geom_point(size = 2, stroke = 1, fill = NA, shape = 21) +
  scale_color_manual(values = cols) +
  scale_fill_manual(values = fills) +
  Yuri_theme
```

# 机器学习
## 监督学习
- 线性回归
- 逻辑回归
- 线型判别分析
- 决策树
- 朴素贝叶斯
- k邻近
- 学习向量量化
- 支持向量机
- 随机森林
- AdaBoost

## 非监督学习
- 高斯混合模型
- 限制波尔兹曼机
- K-means聚类
- 最大期望算法

# 简单线性回归
怀孕情况;血糖;血压;皮肤厚度;胰岛素水平;体重指数;糖尿病谱系功能;年龄;糖尿病诊断结果
```{r}
data <- import("D:/desktop/book/tidybook/data/diabetes.xlsx")
```
研究问题:根据血糖情况来预测胰岛素水平

```{r}
data %>%
  ggplot(., aes(x = Glucose, y = Insulin)) +
  geom_point() +
  stat_smooth() +
  Yuri_theme
```

```{r}
data %>%
  slice_dt(Glucose > 0 & Insulin > 0) %>%
  ggplot(., aes(x = Glucose, y = Insulin)) +
  geom_point() +
  stat_smooth() +
  Yuri_theme
```

```{r}
model <- lm(Insulin ~ Glucose, data = data)
model
```

回归线
```{r}
data %>%
  slice_dt(Glucose > 0 & Insulin > 0) %>%
  ggplot(., aes(x = Glucose, y = Insulin)) +
  geom_point() +
  stat_smooth(method = lm) +
  Yuri_theme
```

# Logistic模型
- 寻找危险因素,找到某些影响因变量的"坏因素",一般可以通过优势比发现危险因素
- 用于预测,可以预测某种情况发生的概率或可能性大小
- 用于判别,判断某个新样本所属的类别
- 因变量为二分类变量
- 因变量和自变量之间不存在线性关系
- 没有关于自变量分布的假设条件,可以是连续变量,离散变量和虚拟变量

创建回归模型的函数:`glm(变量之间的关系的符号,数据集,指定模型的细节)`

|类型|方法|
|-:|:-|
|普通二分类logistic回归|`glm`|
|因变量多分类logistic回归|---|
|有序分类因变量|`MASS::polrb`|
|无序分类因变量|`nnet::multinom`|
|条件logistic回归|`survival::clogit`|

```{r}
x <- seq(from = -10, to = 10, by = 0.01)
y <- exp(x) / (1 + exp(x))
ggplot(data = NULL, mapping = aes(x = x, y = y)) +
  geom_line(color = "blue", size = 1)
```

# 案例1
```{r}
input <- mtcars[, c("am", "cyl", "hp", "wt")]
head(input)
m.data <- glm(formula = am ~ cyl + hp + wt, data = input, family = binomial)
print(summary(m.data))
```
在总结中,对于变量"cyl"和"hp",最后一列中的p值大于0.05,我们认为它们对变量"am"的值有贡献是无关紧要的,只有重量(wt)影响该回归模型中的"am"值

# 案例2
```{r}
data(Affairs, package = "AER")
df <- Affairs
df$ynaffairs <- ifelse(df$affairs > 0, 1, 0)
table(df$ynaffairs)
df$ynaffairs <- factor(df$ynaffairs,
  levels = c(0, 1),
  labels = c("No", "Yes")
)
table(df$ynaffairs)
fit.full <- glm(ynaffairs ~ gender + age + yearsmarried + children + religiousness + education + occupation + rating, data = df, family = binomial())
summary(fit.full)
```

根据回归系数的P值可以看到性别,是否有孩子,学历,职业对方程的贡献都不显著.去除这些变量重新拟合模型

```{r}
fit.reduced <- glm(ynaffairs ~ age + yearsmarried + religiousness + rating, data = df, family = binomial())
anova(fit.full, fit.reduced, test = "Chisq")
```

可以看到结果中p值等于0.2108大于0.05，表明四个变量和9个变量的模型拟合程度没有差别

# 接下来是评价变量对结果概率的影响
## 构造一个测试集
```{r}
testdata <- data.frame(
  rating = c(1, 2, 3, 4, 5),
  age = mean(df$age),
  yearsmarried = mean(df$yearsmarried),
  religiousness = mean(df$religiousness)
)
testdata$prob <- predict(fit.reduced,
  newdata = testdata,
  type = "response"
)
ggplot(testdata, aes(x = rating, y = prob)) +
  geom_col(aes(fill = factor(rating)), show.legend = F) +
  geom_label(aes(label = round(prob, 2))) +
  Yuri_theme
```

# 随机森林
(randomForest)
```{r}
set.seed(2022)
data("iris") -> data
trainlist <- createDataPartition(iris$Species, p = 0.8, list = F)
trainset <- iris[trainlist, ]
testset <- iris[-trainlist, ]
```

## 建模
```{r}
set.seed(2022)
rf.train <- randomForest(as.factor(Species) ~ .,
  data = trainset,
  importance = T,
  na.action = na.pass, # 略过缺失值
  ntree = 500
)

plot(rf.train, main = "randomforest origin")
rf.train
```

## 预测
```{r}
set.seed(2022)
rf.test <- predict(rf.train, newdata = testset, type = "class")
rf.cf <- caret::confusionMatrix(as.factor(rf.test), as.factor(testset$Species), )
rf.test
rf.cf
```

## ROC
```{r}
rf.test2 <- predict(rf.train, newdata = testset, type = "prob")
head(rf.test2)
roc.rf <- multiclass.roc(testset$Species, rf.test2)
roc.rf
```

randomForest()函数中的两个重要参数为ntree和mtry,其中ntree为包含的基分类器个数,默认为500;mtry为每个决策树包含的变量个数,默认为logN,数据量不大时可以循环选择最优参数值,eval = F
